diff --git a/arch/x86/kvm/Makefile b/arch/x86/kvm/Makefile
index f9dddb8cb466..a4c0e75c990e 100644
--- a/arch/x86/kvm/Makefile
+++ b/arch/x86/kvm/Makefile
@@ -8,7 +8,7 @@ include $(srctree)/virt/kvm/Makefile.kvm
 kvm-y			+= x86.o emulate.o i8259.o irq.o lapic.o \
 			   i8254.o ioapic.o irq_comm.o cpuid.o pmu.o mtrr.o \
 			   debugfs.o mmu/mmu.o mmu/page_track.o \
-			   mmu/spte.o
+			   mmu/spte.o kvm_tracer_hooks.o
 
 kvm-$(CONFIG_X86_64) += mmu/tdp_iter.o mmu/tdp_mmu.o
 kvm-$(CONFIG_KVM_HYPERV) += hyperv.o
diff --git a/arch/x86/kvm/kvm_tracer_hooks.c b/arch/x86/kvm/kvm_tracer_hooks.c
new file mode 100644
index 000000000000..5a8df6b10964
--- /dev/null
+++ b/arch/x86/kvm/kvm_tracer_hooks.c
@@ -0,0 +1,76 @@
+#include <linux/kvm_host.h>
+#include "vmx/vmx.h"
+
+static int kvm_tracer_handle_debug_exception_stub(struct kvm_vcpu *vcpu, u32 intr_info, u64 dr6)
+{
+	return 1;
+}
+
+static int kvm_tracer_handle_ept_violation_stub(struct kvm_vcpu *vcpu, unsigned long gpa, unsigned long exit_qualification)
+{
+	return 0;
+}
+
+static int kvm_tracer_vm_create_stub(struct kvm *kvm)
+{
+	return 0;
+}
+
+static void kvm_tracer_vm_destroy_stub(struct kvm *kvm)
+{
+	/* Stub implementation - does nothing */
+}
+
+static int kvm_tracer_vcpu_create_stub(struct kvm_vcpu *vcpu)
+{
+	return 0;
+}
+
+static void kvm_tracer_vcpu_destroy_stub(struct kvm_vcpu *vcpu)
+{
+	/* Stub implementation - does nothing */
+}
+
+int (*kvm_tracer_handle_debug_exception_fn)(struct kvm_vcpu *vcpu, u32 intr_info, u64 dr6) = kvm_tracer_handle_debug_exception_stub;
+int (*kvm_tracer_handle_ept_violation_fn)(struct kvm_vcpu *vcpu, unsigned long gpa, unsigned long exit_qualification) = kvm_tracer_handle_ept_violation_stub;
+int (*kvm_tracer_vm_create_fn)(struct kvm *kvm) = kvm_tracer_vm_create_stub;
+void (*kvm_tracer_vm_destroy_fn)(struct kvm *kvm) = kvm_tracer_vm_destroy_stub;
+int (*kvm_tracer_vcpu_create_fn)(struct kvm_vcpu *vcpu) = kvm_tracer_vcpu_create_stub;
+void (*kvm_tracer_vcpu_destroy_fn)(struct kvm_vcpu *vcpu) = kvm_tracer_vcpu_destroy_stub;
+
+int kvm_tracer_register_functions(int (*debug_exception_fn)(struct kvm_vcpu *, u32, u64),
+                                 int (*ept_violation_fn)(struct kvm_vcpu *, unsigned long, unsigned long),
+                                 int (*vm_create_fn)(struct kvm *),
+                                 void (*vm_destroy_fn)(struct kvm *),
+                                 int (*vcpu_create_fn)(struct kvm_vcpu *),
+                                 void (*vcpu_destroy_fn)(struct kvm_vcpu *))
+{
+	kvm_tracer_handle_debug_exception_fn = debug_exception_fn;
+	kvm_tracer_handle_ept_violation_fn = ept_violation_fn;
+	kvm_tracer_vm_create_fn = vm_create_fn;
+	kvm_tracer_vm_destroy_fn = vm_destroy_fn;
+	kvm_tracer_vcpu_create_fn = vcpu_create_fn;
+	kvm_tracer_vcpu_destroy_fn = vcpu_destroy_fn;
+	
+	return 0;
+}
+
+void kvm_tracer_unregister_functions(void)
+{
+	kvm_tracer_handle_debug_exception_fn = kvm_tracer_handle_debug_exception_stub;
+	kvm_tracer_handle_ept_violation_fn = kvm_tracer_handle_ept_violation_stub;
+	kvm_tracer_vm_create_fn = kvm_tracer_vm_create_stub;
+	kvm_tracer_vm_destroy_fn = kvm_tracer_vm_destroy_stub;
+	kvm_tracer_vcpu_create_fn = kvm_tracer_vcpu_create_stub;
+	kvm_tracer_vcpu_destroy_fn = kvm_tracer_vcpu_destroy_stub;
+}
+
+EXPORT_SYMBOL_GPL(kvm_tracer_handle_debug_exception_fn);
+EXPORT_SYMBOL_GPL(kvm_tracer_handle_ept_violation_fn);
+EXPORT_SYMBOL_GPL(kvm_tracer_vm_create_fn);
+EXPORT_SYMBOL_GPL(kvm_tracer_vm_destroy_fn);
+EXPORT_SYMBOL_GPL(kvm_tracer_vcpu_create_fn);
+EXPORT_SYMBOL_GPL(kvm_tracer_vcpu_destroy_fn);
+
+EXPORT_SYMBOL_GPL(kvm_tracer_register_functions);
+EXPORT_SYMBOL_GPL(kvm_tracer_unregister_functions);
diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index eec0aa13e002..34046f39a662 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -5337,6 +5337,11 @@ static int handle_exception_nmi(struct kvm_vcpu *vcpu)
 	switch (ex_no) {
 	case DB_VECTOR:
 		dr6 = vmx_get_exit_qual(vcpu);
+
+        if (kvm_tracer_handle_debug_exception_fn(vcpu, intr_info, dr6) == 0) {
+            return 1;
+        }
+		
 		if (!(vcpu->guest_debug &
 		      (KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP))) {
 			/*
@@ -5830,6 +5835,11 @@ static int handle_ept_violation(struct kvm_vcpu *vcpu)
 		vmcs_set_bits(GUEST_INTERRUPTIBILITY_INFO, GUEST_INTR_STATE_NMI);
 
 	gpa = vmcs_read64(GUEST_PHYSICAL_ADDRESS);
+
+	if (kvm_tracer_handle_ept_violation_fn(vcpu, (unsigned long)gpa, exit_qualification) == 1) {
+		return 1;
+	}
+
 	trace_kvm_page_fault(vcpu, gpa, exit_qualification);
 
 	/* Is it a read fault? */
@@ -7577,6 +7587,7 @@ int vmx_vcpu_create(struct kvm_vcpu *vcpu)
 
 	BUILD_BUG_ON(offsetof(struct vcpu_vmx, vcpu) != 0);
 	vmx = to_vmx(vcpu);
+    memset(&vmx->tracer_state, 0, sizeof(vmx->tracer_state));
 
 	INIT_LIST_HEAD(&vmx->pi_wakeup_list);
 
@@ -8767,4 +8778,66 @@ static int __init vmx_init(void)
 	kvm_x86_vendor_exit();
 	return r;
 }
+
+unsigned long kvm_tracer_vmcs_readl(unsigned long field)
+{
+	return vmcs_readl(field);
+}
+
+void kvm_tracer_vmcs_writel(unsigned long field, unsigned long value)
+{
+	vmcs_writel(field, value);
+}
+
+u64 kvm_tracer_vmcs_read64(unsigned long field)
+{
+	return vmcs_read64(field);
+}
+
+void kvm_tracer_vmcs_write64(unsigned long field, u64 value)
+{
+	vmcs_write64(field, value);
+}
+
+u32 kvm_tracer_vmcs_read32(unsigned long field)
+{
+	return vmcs_read32(field);
+}
+
+void kvm_tracer_vmcs_write32(unsigned long field, u32 value)
+{
+	vmcs_write32(field, value);
+}
+
+u16 kvm_tracer_vmcs_read16(unsigned long field)
+{
+	return vmcs_read16(field);
+}
+
+void kvm_tracer_vmcs_write16(unsigned long field, u16 value)
+{
+	vmcs_write16(field, value);
+}
+
+void kvm_tracer_ept_sync_context(u64 eptp)
+{
+	ept_sync_context(eptp);
+}
+
+EXPORT_SYMBOL_GPL(kvm_tracer_vmcs_readl);
+EXPORT_SYMBOL_GPL(kvm_tracer_vmcs_writel);
+EXPORT_SYMBOL_GPL(kvm_tracer_vmcs_read64);
+EXPORT_SYMBOL_GPL(kvm_tracer_vmcs_write64);
+EXPORT_SYMBOL_GPL(kvm_tracer_vmcs_read32);
+EXPORT_SYMBOL_GPL(kvm_tracer_vmcs_write32);
+EXPORT_SYMBOL_GPL(kvm_tracer_vmcs_read16);
+EXPORT_SYMBOL_GPL(kvm_tracer_vmcs_write16);
+EXPORT_SYMBOL_GPL(kvm_tracer_ept_sync_context);
+EXPORT_SYMBOL_GPL(current_vmcs);
+EXPORT_SYMBOL_GPL(vmcs_field_to_evmcs_1);
+EXPORT_SYMBOL_GPL(nr_evmcs_1_fields);
+EXPORT_SYMBOL_GPL(vmwrite_error);
+EXPORT_SYMBOL_GPL(vmread_error);
+EXPORT_SYMBOL_GPL(__kvm_is_using_evmcs);
+
 module_init(vmx_init);
diff --git a/arch/x86/kvm/vmx/vmx.h b/arch/x86/kvm/vmx/vmx.h
index 951e44dc9d0e..5d023fdba88c 100644
--- a/arch/x86/kvm/vmx/vmx.h
+++ b/arch/x86/kvm/vmx/vmx.h
@@ -27,6 +27,13 @@
 
 #define MAX_NR_LOADSTORE_MSRS	8
 
+struct kvm_tracer_state {
+    bool tracer_enabled;
+    u64 breakpoint_addresses[4];
+    u64 breakpoint_types[4];
+    bool breakpoints_active;
+};
+
 struct vmx_msrs {
 	unsigned int		nr;
 	struct vmx_msr_entry	val[MAX_NR_LOADSTORE_MSRS];
@@ -248,6 +255,7 @@ struct nested_vmx {
 
 struct vcpu_vmx {
 	struct kvm_vcpu       vcpu;
+	struct kvm_tracer_state tracer_state;
 	u8                    fail;
 	u8		      x2apic_msr_bitmap_mode;
 
@@ -758,4 +766,23 @@ static inline void vmx_segment_cache_clear(struct vcpu_vmx *vmx)
 	vmx->segment_cache.bitmask = 0;
 }
 
+/*
+ * KVM Tracer Function Pointer Declarations
+ * These are shared across all KVM modules
+ */
+extern int (*kvm_tracer_handle_debug_exception_fn)(struct kvm_vcpu *vcpu, u32 intr_info, u64 dr6);
+extern int (*kvm_tracer_handle_ept_violation_fn)(struct kvm_vcpu *vcpu, unsigned long gpa, unsigned long exit_qualification);
+extern int (*kvm_tracer_vm_create_fn)(struct kvm *kvm);
+extern void (*kvm_tracer_vm_destroy_fn)(struct kvm *kvm);
+extern int (*kvm_tracer_vcpu_create_fn)(struct kvm_vcpu *vcpu);
+extern void (*kvm_tracer_vcpu_destroy_fn)(struct kvm_vcpu *vcpu);
+
+extern int kvm_tracer_register_functions(int (*debug_exception_fn)(struct kvm_vcpu *, u32, u64),
+                                        int (*ept_violation_fn)(struct kvm_vcpu *, unsigned long, unsigned long),
+                                        int (*vm_create_fn)(struct kvm *),
+                                        void (*vm_destroy_fn)(struct kvm *),
+                                        int (*vcpu_create_fn)(struct kvm_vcpu *),
+                                        void (*vcpu_destroy_fn)(struct kvm_vcpu *));
+extern void kvm_tracer_unregister_functions(void);
+
 #endif /* __KVM_X86_VMX_H */
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index be7bb6d20129..aed8a9fe6aba 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -33,6 +33,7 @@
 #include "lapic.h"
 #include "xen.h"
 #include "smm.h"
+#include "vmx/vmx.h"
 
 #include <linux/clocksource.h>
 #include <linux/interrupt.h>
@@ -227,6 +228,7 @@ EXPORT_SYMBOL_GPL(allow_smaller_maxphyaddr);
 bool __read_mostly enable_apicv = true;
 EXPORT_SYMBOL_GPL(enable_apicv);
 
+
 const struct _kvm_stats_desc kvm_vm_stats_desc[] = {
 	KVM_GENERIC_VM_STATS(),
 	STATS_DESC_COUNTER(VM, mmu_shadow_zapped),
@@ -12340,6 +12342,7 @@ int kvm_arch_vcpu_create(struct kvm_vcpu *vcpu)
 	if (r)
 		goto free_guest_fpu;
 
+	kvm_tracer_vcpu_create_fn(vcpu);
 	kvm_xen_init_vcpu(vcpu);
 	vcpu_load(vcpu);
 	kvm_vcpu_after_set_cpuid(vcpu);
@@ -12404,6 +12407,7 @@ void kvm_arch_vcpu_destroy(struct kvm_vcpu *vcpu)
 	kvm_xen_destroy_vcpu(vcpu);
 	kvm_hv_vcpu_uninit(vcpu);
 	kvm_pmu_destroy(vcpu);
+	kvm_tracer_vcpu_destroy_fn(vcpu);
 	kfree(vcpu->arch.mce_banks);
 	kfree(vcpu->arch.mci_ctl2_banks);
 	kvm_free_lapic(vcpu);
@@ -14010,6 +14014,82 @@ int kvm_sev_es_string_io(struct kvm_vcpu *vcpu, unsigned int size,
 }
 EXPORT_SYMBOL_GPL(kvm_sev_es_string_io);
 
+int kvm_tracer_get_regs(struct kvm_vcpu *vcpu, struct kvm_regs *regs)
+{
+	if (vcpu->kvm->arch.has_protected_state &&
+	    vcpu->arch.guest_state_protected)
+		return -EINVAL;
+
+	if (vcpu->arch.emulate_regs_need_sync_to_vcpu) {
+		emulator_writeback_register_cache(vcpu->arch.emulate_ctxt);
+		vcpu->arch.emulate_regs_need_sync_to_vcpu = false;
+	}
+
+	regs->rax = kvm_rax_read(vcpu);
+	regs->rbx = kvm_rbx_read(vcpu);
+	regs->rcx = kvm_rcx_read(vcpu);
+	regs->rdx = kvm_rdx_read(vcpu);
+	regs->rsi = kvm_rsi_read(vcpu);
+	regs->rdi = kvm_rdi_read(vcpu);
+	regs->rsp = kvm_rsp_read(vcpu);
+	regs->rbp = kvm_rbp_read(vcpu);
+#ifdef CONFIG_X86_64
+	regs->r8 = kvm_r8_read(vcpu);
+	regs->r9 = kvm_r9_read(vcpu);
+	regs->r10 = kvm_r10_read(vcpu);
+	regs->r11 = kvm_r11_read(vcpu);
+	regs->r12 = kvm_r12_read(vcpu);
+	regs->r13 = kvm_r13_read(vcpu);
+	regs->r14 = kvm_r14_read(vcpu);
+	regs->r15 = kvm_r15_read(vcpu);
+#endif
+	regs->rip = kvm_rip_read(vcpu);
+	regs->rflags = kvm_get_rflags(vcpu);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(kvm_tracer_get_regs);
+
+int kvm_tracer_set_regs(struct kvm_vcpu *vcpu, struct kvm_regs *regs)
+{
+	if (vcpu->kvm->arch.has_protected_state &&
+	    vcpu->arch.guest_state_protected)
+		return -EINVAL;
+
+	vcpu->arch.emulate_regs_need_sync_from_vcpu = true;
+	vcpu->arch.emulate_regs_need_sync_to_vcpu = false;
+
+	kvm_rax_write(vcpu, regs->rax);
+	kvm_rbx_write(vcpu, regs->rbx);
+	kvm_rcx_write(vcpu, regs->rcx);
+	kvm_rdx_write(vcpu, regs->rdx);
+	kvm_rsi_write(vcpu, regs->rsi);
+	kvm_rdi_write(vcpu, regs->rdi);
+	kvm_rsp_write(vcpu, regs->rsp);
+	kvm_rbp_write(vcpu, regs->rbp);
+#ifdef CONFIG_X86_64
+	kvm_r8_write(vcpu, regs->r8);
+	kvm_r9_write(vcpu, regs->r9);
+	kvm_r10_write(vcpu, regs->r10);
+	kvm_r11_write(vcpu, regs->r11);
+	kvm_r12_write(vcpu, regs->r12);
+	kvm_r13_write(vcpu, regs->r13);
+	kvm_r14_write(vcpu, regs->r14);
+	kvm_r15_write(vcpu, regs->r15);
+#endif
+	kvm_rip_write(vcpu, regs->rip);
+	kvm_set_rflags(vcpu, regs->rflags | X86_EFLAGS_FIXED);
+
+	vcpu->arch.exception.pending = false;
+	vcpu->arch.exception_vmexit.pending = false;
+
+	kvm_make_request(KVM_REQ_EVENT, vcpu);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(kvm_tracer_set_regs);
+EXPORT_SYMBOL_GPL(kvm_mmu_gva_to_gpa_system);
+
 EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_entry);
 EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_exit);
 EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_fast_mmio);
diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
index d0ce45c7b5cd..de6cd3608941 100644
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@ -58,6 +58,7 @@
 #include "async_pf.h"
 #include "kvm_mm.h"
 #include "vfio.h"
+#include "../arch/x86/kvm/vmx/vmx.h"
 
 #include <trace/events/ipi.h>
 
@@ -94,6 +95,7 @@ unsigned int halt_poll_ns_shrink = 2;
 module_param(halt_poll_ns_shrink, uint, 0644);
 EXPORT_SYMBOL_GPL(halt_poll_ns_shrink);
 
+
 /*
  * Allow direct access (from KVM or the CPU) without MMU notifier protection
  * to unpinned pages.
@@ -1156,6 +1158,8 @@ static struct kvm *kvm_create_vm(unsigned long type, const char *fdname)
 	if (r)
 		goto out_err_no_irq_routing;
 
+	kvm_tracer_vm_create_fn(kvm);
+		
 	refcount_set(&kvm->users_count, 1);
 
 	for (i = 0; i < kvm_arch_nr_memslot_as_ids(kvm); i++) {
@@ -1275,6 +1279,7 @@ static void kvm_destroy_vm(struct kvm *kvm)
 	list_del(&kvm->vm_list);
 	mutex_unlock(&kvm_lock);
 	kvm_arch_pre_destroy_vm(kvm);
+	kvm_tracer_vm_destroy_fn(kvm);
 
 	kvm_free_irq_routing(kvm);
 	for (i = 0; i < KVM_NR_BUSES; i++) {
